---
title: "Motor Trend: Which is better Manual or Automatic?"
# author: "Frank Jung"
# date: "22 September 2015"
output:
  pdf_document:
    fig_caption: no
    fig_crop: no
    latex_engine: xelatex
classoption: legalpaper
---

# Executive Summary

This report seeks to answer the question: Which is better for car mileage:
automatic or manual transmission? Also, can we quantify any mileage differences
between these two transmission types? To answer this question _Motor Trend_ has
surveyed various motor vehicles. In this report we will show that of the many
automobile attributes surveyed, a linear regression model with transmission
type, weight and $\frac {1} {4}$ mile time, provide a better prediction for
mileage than using only the transmission type.

```{r setoptions, echo=FALSE}
require(knitr, quietly = TRUE)
require(ggplot2, quietly = TRUE)
require(scales, quietly = TRUE)

knitr::opts_chunk$set(echo = FALSE, cache = TRUE, cache.path = "cache/",
                      fig.path = "figure/", fig.align = "center")

# load cars dataset
require(datasets, quietly = TRUE)
data(mtcars)
```

# Exploratory Analysis

A data frame with 32 observations on 11 variables.

| Field | Description |
|-------|-------------|
| mpg   | Miles/(US) gallon |
| cyl   | Number of cylinders (`r sort(unique(mtcars$cyl))`) |
| disp  | Displacement (cu.in.) |
| hp    | Gross horsepower |
| drat  | Rear axle ratio |
| wt    | Weight (lb/1000) |
| qsec  | 1/4 mile time (seconds) |
| vs    | [V shaped engine](https://en.wikipedia.org/wiki/V_engine), [Straight engine](https://en.wikipedia.org/wiki/Straight_engine) |
| am    | Transmission (0 = automatic, 1 = manual) |
| gear  | Number of forward gears (`r sort(unique(mtcars$gear))`) |
| carb  | Number of carburettors (`r sort(unique(mtcars$carb))`) |

Table: Fields in mtcars dataset

The sample of the first rows from dataset looks like:

```{r head}
kable(head(mtcars), caption = "Sample from mtcars")
```

How does mileage compare to transmission? The [Figure: Mileage by Transmission
Type](#appendices) indicates that manual transmissions have better
mileage. However, there could be regressors that give better predictions. We
will investigate this further in the following sections.

# Simple Linear Regression Model

Consider a simple linear regression where we predict the mileage (`mpg`) using
just the transmission (`am`), i.e. $mpg \sim am$. See [Figure: Simple Linear
Regression](#appendices). The coefficients of this simple linear regression are:

```{r modelSLR}
modelSLR <- lm(mpg ~ am, mtcars)
modelSLRsum <- summary(modelSLR)
kable(cbind(modelSLRsum$coef, round(confint(modelSLR), 1)), caption = "Model Coefficients")
```

Reassuringly the P-value of the slope coefficient is around
`r prettyNum(round(modelSLRsum$coef[2,4], 5))`, which indicates there is some
amount of linear relationship between mileage and transmission. However, since
the transmission is categorical the predictions made by this model are just
mileage sample means for their respective transmission types as is shown in the
table below:

| Transmission | Prediction | Mileage Sample Mean |
|--------------|------------|--------------------|
| Automatic | `r round(predict(modelSLR, data.frame(am = 0)), 2)` | `r round(mean(with(mtcars, mtcars[am == 0, "mpg"])), 2)` |
| Manual | `r round(predict(modelSLR, data.frame(am = 1)), 2)` | `r round(mean(with(mtcars, mtcars[am == 1, "mpg"])), 2)` |

Table: Model prediction vs mileage sample mean

In [Figure: Fitted vs Residuals for Simple Linear Regression](#appendices) the
plot shows increased variance (heteroscedasticity) about the mean for manual
versus automatic.

Finally, only about `r round(modelSLRsum$adj.r.squared * 100)`% of the
variation ($R^2$) is explained by this model. Can we do better?

# Multi Linear Regression Model

As an alternative look at a multi-variable linear regression. To assist us we
will use the [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion)
step-wise model selection from the [MASS
package](https://cran.r-project.org/web/packages/MASS/index.html). AIC is a
goodness of fit measure that favours smaller residual error in the model, but
penalises the inclusion of further predictors which helps avoiding over fitting.
When comparing models fitted by maximum likelihood to the same data, the smaller
the AIC, the better the fit. The previous simple linear model had a maximum
likelihood (residual standard error) of `r prettyNum(round(modelSLRsum$sigma,2))`
and an AIC of `r round(AIC(modelSLR),2)`.

The best model [found](#appendices) using the AIC stepwise algorithm was:
$mpg \sim wt + qsec + am$. The table below summarises its coefficients:

```{r modelMLR}
library(MASS)
fit <- lm(mpg ~ ., mtcars)
step <- stepAIC(fit, direction = "both", trace = 0)
modelMLR <- lm(mpg ~ wt + qsec + am, mtcars)
modelMLRsum <- summary(modelMLR)
kable(cbind(modelMLRsum$coef, round(confint(modelMLR), 1)), caption = "Model Coefficients")
```

We can see that on average manual transmission cars have
`r round(modelMLRsum$coef[4],2)` MPG better mileage than cars with automatic
transmission.  Weight reduces mileage by `r round(modelMLRsum$coef[2],2)` per
1000 lb increase in weight. While taking longer to do a $\frac {1} {4}$ quarter
mile improves mileage by `r round(modelMLRsum$coef[3],2)` per second increase in
time.

So, how does this model compare to our [Simple Linear Regression
Model](#simple-linear-regression-model)? Below is a table summarising some of
the key statistics we can use to compare these two models:

```{r compare}
fit.models <- c("Simple Linear Regression", "Multi Linear Regression")
fit.r.squared <- c(modelSLRsum$adj.r.squared, modelMLRsum$adj.r.squared)
fit.vif <- 1/(1 - fit.r.squared)
fit.var.residuals <- c(modelSLRsum$sigma, modelMLRsum$sigma)
fit.aic <- c(AIC(modelSLR), AIC(modelMLR))
df <- data.frame("Model" = fit.models, "R Squared" = fit.r.squared, VIF = fit.vif, "Residual Variance" = fit.var.residuals, AIC = fit.aic)
kable(df, caption = "Compare Models")
```

There are a number of things to note from these statistics. Firstly, over
`r round(modelMLRsum$adj.r.squared * 100)`% of the variation ($R^2$) is now
explained by the [Multi Linear Regression
Model](#multi-linear-regression-model). This also relates to the [variance
inflation factor
(VIF)](https://en.wikipedia.org/wiki/Variance_inflation_factor). Furthermore,
the measure of residual variation has reduced. We have also seen an reduction in
AIC.

The [Figure: Fitted vs Residuals for Multi Linear Regression](#appendices) shows
values that are more evenly spread (homoscedasticity), without any distinct
cluster or pattern. This further indicates a better model fit than the Simple
linear Regression Model.

Included in the Appendices is the [Figure: Multi Linear Regression: Normal
Q-Q](#appendices). This shows the models standardised residuals fit to the
expected [Gaussian
distribution](https://en.wikipedia.org/wiki/Normal_distribution).

# Conclusion

The dataset is small with only `r nrow(mtcars)` records. The models could be
improved with more data. That said, a multi-variable linear regression model
provides a better predictor of mileage than the simple linear regression model.
This, however, comes at a small cost of requiring additional regressors, namely
the automobiles weight and the time for a quarter mile.

# References

* Generated from Rmd into PDF using [knitr in RStudio](http://yihui.name/knitr/demo/rstudio/), see also [session information](#appendices)
* [GitHub repository containing project code](https://github.com/frankhjung/regmods-project)

# Appendices

```{r stepwise, fig.cap = "AIC Stepwise Regression", echo = TRUE}
library(MASS)
fit <- lm(mpg ~ ., mtcars)
step <- stepAIC(fit, direction = "both", trace = 0)
step$anova
```

```{r sessionInformation, fig.cap = "Session Information"}
sessionInfo()
```

```{r violinplot, fig.cap = "Milage by Transmission Type"}
mtcars2 <- data.frame(mtcars)
mtcars2$am <- factor(mtcars2$am, labels = c("automatic", "manual"))
ggplot(mtcars2, aes(x = am, y = mpg)) +
    geom_violin() +
    geom_boxplot(width = 0.2, fill = "purple", alpha = 0.4) +
    stat_summary(fun.y = mean, geom = "point", colour = "white", shape = 19, size = 2) +
    theme_light(base_family = "sans", base_size = 11) +
    labs(x = "Transmission Type", y = "Miles/(US) gallon") +
    ggtitle("Milage by Transmission Type")
```

```{r slr, fig.cap = "Simple Linear Regression"}
ggplot(mtcars, aes(x = am, y = mpg)) +
    geom_point(shape = 19, size = 2, colour = "purple") +
    geom_smooth(method = lm) +
    theme_light(base_family = "sans", base_size = 11) +
    scale_x_discrete(breaks = c(0, 1), labels = c("automatic", "manual"), expand = c(0.2, -0.5)) +
    labs(x = "Transmission Type", y = "Miles/(US) gallon") +
    ggtitle("Simple Linear Regression: mpg ~ transmission")
```

```{r risvsfitmodelSLR, fig.cap = "Fitted vs Residuals for Simple Linear Regression"}
qplot(fitted(modelSLR), resid(modelSLR)) +
    geom_hline(yintercept = 0, colour = "red") +
    geom_point(shape = 19, size = 2, colour = "purple") +
    theme_light(base_family = "sans", base_size = 11) +
    xlab("Fitted values (MPG)") +
    ylab("Residuals") +
    ggtitle("Simple Linear Regression fitted values vs residuals")
```

```{r risvsfitmodelMLR, fig.cap = "Fitted vs Residuals for Multi Linear Regression"}
qplot(fitted(modelMLR), resid(modelMLR)) +
    geom_hline(yintercept = 0, colour = "red") +
    geom_point(shape = 19, size = 2, colour = "purple") +
    theme_light(base_family = "sans", base_size = 11) +
    xlab("Fitted values (MPG)") +
    ylab("Residuals") +
    ggtitle("Multi Linear Regression: fitted values vs residuals")
```

```{r plotmodelMLR, fig.cap = "Multi Linear Regression: Normal Q-Q"}
plot(modelMLR, which = c(2), pch = 19, col = c("purple"))
```
